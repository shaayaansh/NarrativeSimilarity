{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Notebook\n",
    "\n",
    "Prepare and merge narrative similarity data, alignment structure, ratings, full text, and extracted events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f31222ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d31f28f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modeling_overall: /Users/shayan/Projects/NarrativeSimilarity/src/../data/Modeling Data/modeling_data_overall.csv | exists=True\n",
      "modeling_structural: /Users/shayan/Projects/NarrativeSimilarity/src/../data/Modeling Data/modeling_data_structural.csv | exists=True\n",
      "pairs: /Users/shayan/Projects/NarrativeSimilarity/src/../data/Qualtrics_Story_Pairs_sampled_clean.csv | exists=True\n",
      "alignments: /Users/shayan/Projects/NarrativeSimilarity/src/../data/Alignment/sampled_story_alignments.json | exists=True\n"
     ]
    }
   ],
   "source": [
    "base = Path.cwd()\n",
    "data_dir = base / '..' / 'data'\n",
    "\n",
    "paths = {\n",
    "    'modeling_overall': data_dir / 'Modeling Data' / 'modeling_data_overall.csv',\n",
    "    'modeling_structural': data_dir / 'Modeling Data' / 'modeling_data_structural.csv',\n",
    "    'pairs': data_dir / 'Qualtrics_Story_Pairs_sampled_clean.csv',\n",
    "    'alignments': data_dir / 'Alignment' / 'sampled_story_alignments.json',\n",
    "}\n",
    "\n",
    "for name, p in paths.items():\n",
    "    print(f'{name}: {p} | exists={p.exists()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1468ea70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modeling_overall_df: (374, 18)\n",
      "modeling_structural_df: (364, 18)\n",
      "pairs_df: (120, 10)\n",
      "alignments: 120\n"
     ]
    }
   ],
   "source": [
    "modeling_overall_df = pd.read_csv(paths['modeling_overall'])\n",
    "modeling_structural_df = pd.read_csv(paths['modeling_structural'])\n",
    "pairs_df = pd.read_csv(paths['pairs'])\n",
    "\n",
    "with open(paths['alignments'], 'r', encoding='utf-8') as f:\n",
    "    alignments = json.load(f)\n",
    "\n",
    "print('modeling_overall_df:', modeling_overall_df.shape)\n",
    "print('modeling_structural_df:', modeling_structural_df.shape)\n",
    "print('pairs_df:', pairs_df.shape)\n",
    "print('alignments:', len(alignments))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ac95184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PairID</th>\n",
       "      <th>num_matches</th>\n",
       "      <th>num_unmatched_a</th>\n",
       "      <th>num_unmatched_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P131</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P189</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P196</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P072</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PairID  num_matches  num_unmatched_a  num_unmatched_b\n",
       "0   P131            0                4                2\n",
       "1   P189            0                1                6\n",
       "2   P000            0                5                3\n",
       "3   P196            0                3                1\n",
       "4   P072            0                7               10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignment_df = pd.DataFrame([\n",
    "    {\n",
    "        'PairID': item.get('PairID'),\n",
    "        'EventsA_align': item.get('EventsA', []),\n",
    "        'EventsB_align': item.get('EventsB', []),\n",
    "        'alignment': item.get('alignment', {}),\n",
    "        'matches': item.get('alignment', {}).get('matches', []),\n",
    "        'unmatched_a': item.get('alignment', {}).get('unmatched_a', []),\n",
    "        'unmatched_b': item.get('alignment', {}).get('unmatched_b', []),\n",
    "        'num_matches': len(item.get('alignment', {}).get('matches', [])),\n",
    "        'num_unmatched_a': len(item.get('alignment', {}).get('unmatched_a', [])),\n",
    "        'num_unmatched_b': len(item.get('alignment', {}).get('unmatched_b', [])),\n",
    "    }\n",
    "    for item in alignments\n",
    "])\n",
    "\n",
    "for df in [modeling_overall_df, modeling_structural_df, pairs_df, alignment_df]:\n",
    "    df['PairID'] = df['PairID'].astype(str).str.strip()\n",
    "\n",
    "alignment_df[['PairID', 'num_matches', 'num_unmatched_a', 'num_unmatched_b']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf2925a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall_merged_df: (374, 34)\n",
      "structural_merged_df: (364, 34)\n",
      "pair_level_merged_df: (120, 17)\n"
     ]
    }
   ],
   "source": [
    "pair_meta_cols = ['PairID', 'bucket', 'sim_full', 'sim_event', 'FullA', 'FullB', 'EventsA', 'EventsB']\n",
    "pair_meta_df = pairs_df[pair_meta_cols].drop_duplicates(subset=['PairID'])\n",
    "\n",
    "overall_merged_df = modeling_overall_df.merge(alignment_df, on='PairID', how='left').merge(\n",
    "    pair_meta_df, on='PairID', how='left', suffixes=('', '_pairs')\n",
    ")\n",
    "\n",
    "structural_merged_df = modeling_structural_df.merge(alignment_df, on='PairID', how='left').merge(\n",
    "    pair_meta_df, on='PairID', how='left', suffixes=('', '_pairs')\n",
    ")\n",
    "\n",
    "pair_level_merged_df = alignment_df.merge(pair_meta_df, on='PairID', how='left')\n",
    "\n",
    "print('overall_merged_df:', overall_merged_df.shape)\n",
    "print('structural_merged_df:', structural_merged_df.shape)\n",
    "print('pair_level_merged_df:', pair_level_merged_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d799562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core columns available for modeling:\n",
      "['PairID', 'bucket', 'sim_full', 'sim_event', 'num_matches', 'num_unmatched_a', 'num_unmatched_b', 'FullA', 'FullB', 'EventsA', 'EventsB', 'full_rating', 'event_rating']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PairID</th>\n",
       "      <th>bucket</th>\n",
       "      <th>sim_full</th>\n",
       "      <th>sim_event</th>\n",
       "      <th>num_matches</th>\n",
       "      <th>num_unmatched_a</th>\n",
       "      <th>num_unmatched_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P131</td>\n",
       "      <td>HL</td>\n",
       "      <td>0.407780</td>\n",
       "      <td>0.123518</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P189</td>\n",
       "      <td>HL</td>\n",
       "      <td>0.446355</td>\n",
       "      <td>0.069382</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P000</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.746363</td>\n",
       "      <td>0.483632</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P196</td>\n",
       "      <td>HL</td>\n",
       "      <td>0.454492</td>\n",
       "      <td>0.125337</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P072</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.381345</td>\n",
       "      <td>0.320885</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PairID bucket  sim_full  sim_event  num_matches  num_unmatched_a  \\\n",
       "0   P131     HL  0.407780   0.123518            0                4   \n",
       "1   P189     HL  0.446355   0.069382            0                1   \n",
       "2   P000     HH  0.746363   0.483632            0                5   \n",
       "3   P196     HL  0.454492   0.125337            0                3   \n",
       "4   P072     HH  0.381345   0.320885            0                7   \n",
       "\n",
       "   num_unmatched_b  \n",
       "0                2  \n",
       "1                6  \n",
       "2                3  \n",
       "3                1  \n",
       "4               10  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Core columns available for modeling:')\n",
    "print([\n",
    "    'PairID', 'bucket', 'sim_full', 'sim_event',\n",
    "    'num_matches', 'num_unmatched_a', 'num_unmatched_b',\n",
    "    'FullA', 'FullB', 'EventsA', 'EventsB',\n",
    "    'full_rating', 'event_rating'\n",
    "])\n",
    "\n",
    "pair_level_merged_df[['PairID', 'bucket', 'sim_full', 'sim_event', 'num_matches', 'num_unmatched_a', 'num_unmatched_b']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc376b77",
   "metadata": {},
   "source": [
    "## Alignment Distance: `D_alignment`\n",
    "\n",
    "This section computes `D_alignment` using the full alignment dictionary and event-level aligned pairs.\n",
    "\n",
    "- `cost_skip = (E_A - |A_aligned|) + (E_B - |B_aligned|)` where aligned sets come from all match groups.\n",
    "- `cost_reorder` is inversion count over the induced `B` sequence from aligned event pairs `(i, j)` after sorting by `i`.\n",
    "- `Z = |A_pairs|(|A_pairs|-1)/2 + (E_A + E_B)`.\n",
    "\n",
    "So `D_alignment = (cost_reorder + cost_skip) / Z`, and `alignment_similarity = 1 - D_alignment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6730aaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       D_alignment  alignment_similarity\n",
      "count   120.000000            120.000000\n",
      "mean      0.867946              0.132054\n",
      "std       0.272089              0.272089\n",
      "min       0.000000              0.000000\n",
      "25%       1.000000              0.000000\n",
      "50%       1.000000              0.000000\n",
      "75%       1.000000              0.000000\n",
      "max       1.000000              1.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PairID</th>\n",
       "      <th>cost_reorder</th>\n",
       "      <th>cost_skip</th>\n",
       "      <th>D_alignment</th>\n",
       "      <th>alignment_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PairID  cost_reorder  cost_skip  D_alignment  alignment_similarity\n",
       "0   P131           0.0        6.0          1.0                   0.0\n",
       "1   P189           0.0        7.0          1.0                   0.0\n",
       "2   P000           0.0        8.0          1.0                   0.0\n",
       "3   P196           0.0        4.0          1.0                   0.0\n",
       "4   P072           0.0       17.0          1.0                   0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_alignment_distance(row):\n",
    "    # Uses full alignment dictionary with event-level aligned pairs.\n",
    "    alignment = row.get('alignment') or {}\n",
    "    matches = alignment.get('matches', []) or []\n",
    "\n",
    "    events_a = row.get('EventsA_align') or []\n",
    "    events_b = row.get('EventsB_align') or []\n",
    "    E_A = len(events_a)\n",
    "    E_B = len(events_b)\n",
    "\n",
    "    aligned_a = set()\n",
    "    aligned_b = set()\n",
    "    aligned_pairs = []\n",
    "\n",
    "    # Build event-level aligned pairs A_pairs via many-to-many expansion.\n",
    "    for match in matches:\n",
    "        a_inds = match.get('a_indices', []) or []\n",
    "        b_inds = match.get('b_indices', []) or []\n",
    "\n",
    "        aligned_a.update(a_inds)\n",
    "        aligned_b.update(b_inds)\n",
    "\n",
    "        for i in a_inds:\n",
    "            for j in b_inds:\n",
    "                aligned_pairs.append((i, j))\n",
    "\n",
    "    cost_skip = (E_A - len(aligned_a)) + (E_B - len(aligned_b))\n",
    "\n",
    "    # Reordering inversions in B after sorting aligned pairs by A index.\n",
    "    aligned_pairs.sort(key=lambda x: x[0])\n",
    "    b_sequence = [j for (_, j) in aligned_pairs]\n",
    "\n",
    "    cost_reorder = 0\n",
    "    for i in range(len(b_sequence)):\n",
    "        for j in range(i + 1, len(b_sequence)):\n",
    "            if b_sequence[i] > b_sequence[j]:\n",
    "                cost_reorder += 1\n",
    "\n",
    "    num_pairs = len(aligned_pairs)\n",
    "    max_reorder = num_pairs * (num_pairs - 1) / 2\n",
    "    Z = max_reorder + (E_A + E_B)\n",
    "\n",
    "    D_alignment = (cost_reorder + cost_skip) / Z if Z > 0 else 0.0\n",
    "\n",
    "    return pd.Series({\n",
    "        'cost_reorder': float(cost_reorder),\n",
    "        'cost_skip': float(cost_skip),\n",
    "        'D_alignment': float(D_alignment),\n",
    "        'alignment_similarity': float(1 - D_alignment),\n",
    "    })\n",
    "\n",
    "alignment_distance_df = alignment_df.apply(compute_alignment_distance, axis=1)\n",
    "alignment_df = pd.concat([alignment_df, alignment_distance_df], axis=1)\n",
    "\n",
    "print(alignment_df[['D_alignment', 'alignment_similarity']].describe().to_string())\n",
    "alignment_df[['PairID', 'cost_reorder', 'cost_skip', 'D_alignment', 'alignment_similarity']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127ca740",
   "metadata": {},
   "source": [
    "## Target Construction: `event_rating_num`\n",
    "\n",
    "In the next code cell, we prepare participant-level modeling data (one row per participant and `PairID`) by combining overall and structural responses with alignment-derived features.\n",
    "\n",
    "The raw target column is `event_rating` (text labels such as `\"3: moderately similar\"`). We convert this into a numeric target, `event_rating_num`, by extracting the leading integer (for example, `3`).\n",
    "\n",
    "`event_rating_num` is the final target column for prediction models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14ae5e40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participant_model_df shape: (738, 14)\n",
      "target column: event_rating\n",
      "event_rating_num value counts:\n",
      "event_rating_num\n",
      "1.0    363\n",
      "2.0    229\n",
      "3.0    110\n",
      "4.0     36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PairID</th>\n",
       "      <th>PROLIFIC_PID</th>\n",
       "      <th>bucket</th>\n",
       "      <th>sim_full</th>\n",
       "      <th>sim_event</th>\n",
       "      <th>num_matches</th>\n",
       "      <th>num_unmatched_a</th>\n",
       "      <th>num_unmatched_b</th>\n",
       "      <th>FullA</th>\n",
       "      <th>FullB</th>\n",
       "      <th>EventsA</th>\n",
       "      <th>EventsB</th>\n",
       "      <th>event_rating</th>\n",
       "      <th>event_rating_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P010</td>\n",
       "      <td>62029a55ef1cb18a1337c61a</td>\n",
       "      <td>HH</td>\n",
       "      <td>0.564017</td>\n",
       "      <td>0.403043</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>I wanted to be an artist when I was in high sc...</td>\n",
       "      <td>and I suddenly realized something about scienc...</td>\n",
       "      <td>My dad died when I was six \u2014 I saw my mom stru...</td>\n",
       "      <td>I realized I had to pick one thing in science ...</td>\n",
       "      <td>3: moderately similar</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P321</td>\n",
       "      <td>62029a55ef1cb18a1337c61a</td>\n",
       "      <td>LL</td>\n",
       "      <td>0.252370</td>\n",
       "      <td>0.129338</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>five or six bands, you know, 'cause people wou...</td>\n",
       "      <td>something with business. I didn't know exactly...</td>\n",
       "      <td>became the radio station's band \u2014 played 80-10...</td>\n",
       "      <td>I woke up at two o'clock in the morning \u2014 I pa...</td>\n",
       "      <td>2: slightly similar</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P242</td>\n",
       "      <td>62029a55ef1cb18a1337c61a</td>\n",
       "      <td>LH</td>\n",
       "      <td>0.256391</td>\n",
       "      <td>0.463312</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Where were you when you were our age, 22, 23? ...</td>\n",
       "      <td>I actually had no idea that tech was a thing. ...</td>\n",
       "      <td>I was in Chile \u2014 I was about to finish college...</td>\n",
       "      <td>A friend graduated and taught himself how to c...</td>\n",
       "      <td>3: moderately similar</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P361</td>\n",
       "      <td>62029a55ef1cb18a1337c61a</td>\n",
       "      <td>LL</td>\n",
       "      <td>0.253082</td>\n",
       "      <td>0.104825</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>So at Alchemy we are taking the concept of che...</td>\n",
       "      <td>where you weren't truly able to talk about emo...</td>\n",
       "      <td>went and worked at Detroit Country Day School ...</td>\n",
       "      <td>worked up the courage to read a poem at an ope...</td>\n",
       "      <td>1: not similar</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P292</td>\n",
       "      <td>666f2488909bc0331b8563e6</td>\n",
       "      <td>LH</td>\n",
       "      <td>0.218787</td>\n",
       "      <td>0.400481</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I was already a pretty avid diver , and enjoye...</td>\n",
       "      <td>So going back into the time when you were firs...</td>\n",
       "      <td>came down to Miami \u2014 went to law school \u2014 prac...</td>\n",
       "      <td>I came out and had a film \u2014 I started looking ...</td>\n",
       "      <td>1: not similar</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PairID              PROLIFIC_PID bucket  sim_full  sim_event  num_matches  \\\n",
       "0   P010  62029a55ef1cb18a1337c61a     HH  0.564017   0.403043            1   \n",
       "1   P321  62029a55ef1cb18a1337c61a     LL  0.252370   0.129338            0   \n",
       "2   P242  62029a55ef1cb18a1337c61a     LH  0.256391   0.463312            4   \n",
       "3   P361  62029a55ef1cb18a1337c61a     LL  0.253082   0.104825            0   \n",
       "4   P292  666f2488909bc0331b8563e6     LH  0.218787   0.400481            3   \n",
       "\n",
       "   num_unmatched_a  num_unmatched_b  \\\n",
       "0                5                1   \n",
       "1                6                6   \n",
       "2                3                1   \n",
       "3                7                4   \n",
       "4                1                0   \n",
       "\n",
       "                                               FullA  \\\n",
       "0  I wanted to be an artist when I was in high sc...   \n",
       "1  five or six bands, you know, 'cause people wou...   \n",
       "2  Where were you when you were our age, 22, 23? ...   \n",
       "3  So at Alchemy we are taking the concept of che...   \n",
       "4  I was already a pretty avid diver , and enjoye...   \n",
       "\n",
       "                                               FullB  \\\n",
       "0  and I suddenly realized something about scienc...   \n",
       "1  something with business. I didn't know exactly...   \n",
       "2  I actually had no idea that tech was a thing. ...   \n",
       "3  where you weren't truly able to talk about emo...   \n",
       "4  So going back into the time when you were firs...   \n",
       "\n",
       "                                             EventsA  \\\n",
       "0  My dad died when I was six \u2014 I saw my mom stru...   \n",
       "1  became the radio station's band \u2014 played 80-10...   \n",
       "2  I was in Chile \u2014 I was about to finish college...   \n",
       "3  went and worked at Detroit Country Day School ...   \n",
       "4  came down to Miami \u2014 went to law school \u2014 prac...   \n",
       "\n",
       "                                             EventsB           event_rating  \\\n",
       "0  I realized I had to pick one thing in science ...  3: moderately similar   \n",
       "1  I woke up at two o'clock in the morning \u2014 I pa...    2: slightly similar   \n",
       "2  A friend graduated and taught himself how to c...  3: moderately similar   \n",
       "3  worked up the courage to read a poem at an ope...         1: not similar   \n",
       "4  I came out and had a film \u2014 I started looking ...         1: not similar   \n",
       "\n",
       "   event_rating_num  \n",
       "0               3.0  \n",
       "1               2.0  \n",
       "2               3.0  \n",
       "3               1.0  \n",
       "4               1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Participant-level modeling target: event_rating (one row per participant x PairID)\n",
    "target_col = 'event_rating'\n",
    "\n",
    "participant_model_df = pd.concat([overall_merged_df, structural_merged_df], ignore_index=True)\n",
    "\n",
    "# Convert labels like '3: moderately similar' -> 3\n",
    "participant_model_df['event_rating_num'] = (\n",
    "    participant_model_df[target_col]\n",
    "    .astype(str)\n",
    "    .str.extract(r'^(\\d+)')[0]\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "model_feature_cols = [\n",
    "    'PairID', 'PROLIFIC_PID', 'bucket', 'sim_full', 'sim_event',\n",
    "    'num_matches', 'num_unmatched_a', 'num_unmatched_b',\n",
    "    'FullA', 'FullB', 'EventsA', 'EventsB',\n",
    "    'event_rating', 'event_rating_num'\n",
    "]\n",
    "participant_model_df = participant_model_df[model_feature_cols].copy()\n",
    "\n",
    "print('participant_model_df shape:', participant_model_df.shape)\n",
    "print('target column:', target_col)\n",
    "print('event_rating_num value counts:')\n",
    "print(participant_model_df['event_rating_num'].value_counts(dropna=False).sort_index().to_string())\n",
    "participant_model_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95efac63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant-level rows by PairID (first 10):\n",
      "PairID\n",
      "P000     8\n",
      "P004     9\n",
      "P010     4\n",
      "P013    12\n",
      "P017     9\n",
      "P020     7\n",
      "P024    10\n",
      "P031     4\n",
      "P033     7\n",
      "P034     5\n",
      "Average event_rating_num by bucket:\n",
      "bucket\n",
      "HH    2.084158\n",
      "HL    1.434211\n",
      "LH    1.933333\n",
      "LL    1.389937\n"
     ]
    }
   ],
   "source": [
    "print('Participant-level rows by PairID (first 10):')\n",
    "print(participant_model_df.groupby('PairID').size().head(10).to_string())\n",
    "\n",
    "print('Average event_rating_num by bucket:')\n",
    "print(participant_model_df.groupby('bucket')['event_rating_num'].mean().sort_index().to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caae217",
   "metadata": {},
   "source": [
    "## Fit Alignment-Only Model With Intercept\n",
    "\n",
    "Because `D_alignment` is pair-level, we tune an alignment-only linear model against the mean `event_rating_num` per `PairID`:\n",
    "\n",
    "`event_rating_num_mean \u2248 c + alpha * alignment_similarity`\n",
    "\n",
    "where `c` is an intercept (noise/bias term)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51e6fb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair count: 98\n",
      "alpha_hat (pair-level mean target): 3.3954\n",
      "RMSE: 1.4759\n",
      "MAE: 1.3612\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PairID</th>\n",
       "      <th>alignment_similarity</th>\n",
       "      <th>event_rating_num_mean</th>\n",
       "      <th>pred_event_rating_mean_from_alignment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P131</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P072</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P212</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P292</td>\n",
       "      <td>0.96875</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>3.289319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PairID  alignment_similarity  event_rating_num_mean  \\\n",
       "0   P131               0.00000               1.333333   \n",
       "1   P000               0.00000               2.375000   \n",
       "2   P072               0.00000               2.000000   \n",
       "3   P212               0.00000               2.142857   \n",
       "4   P292               0.96875               2.300000   \n",
       "\n",
       "   pred_event_rating_mean_from_alignment  \n",
       "0                               0.000000  \n",
       "1                               0.000000  \n",
       "2                               0.000000  \n",
       "3                               0.000000  \n",
       "4                               3.289319  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rebuild merges so they include D_alignment and full alignment columns.\n",
    "overall_merged_df = modeling_overall_df.merge(alignment_df, on='PairID', how='left').merge(\n",
    "    pair_meta_df, on='PairID', how='left', suffixes=('', '_pairs')\n",
    ")\n",
    "structural_merged_df = modeling_structural_df.merge(alignment_df, on='PairID', how='left').merge(\n",
    "    pair_meta_df, on='PairID', how='left', suffixes=('', '_pairs')\n",
    ")\n",
    "\n",
    "participant_model_df = pd.concat([overall_merged_df, structural_merged_df], ignore_index=True)\n",
    "participant_model_df['event_rating_num'] = (\n",
    "    participant_model_df['event_rating'].astype(str).str.extract(r'^(\\d+)')[0].astype(float)\n",
    ")\n",
    "\n",
    "pair_target_df = (\n",
    "    participant_model_df.groupby('PairID', as_index=False)['event_rating_num']\n",
    "    .mean()\n",
    "    .rename(columns={'event_rating_num': 'event_rating_num_mean'})\n",
    ")\n",
    "\n",
    "pair_model_df = (\n",
    "    alignment_df[['PairID', 'D_alignment', 'alignment_similarity']]\n",
    "    .merge(pair_target_df, on='PairID', how='inner')\n",
    ")\n",
    "\n",
    "x = pair_model_df['alignment_similarity'].astype(float).to_numpy()\n",
    "y = pair_model_df['event_rating_num_mean'].astype(float).to_numpy()\n",
    "valid = np.isfinite(x) & np.isfinite(y)\n",
    "x = x[valid]\n",
    "y = y[valid]\n",
    "\n",
    "X = np.column_stack([np.ones(len(x)), x])\n",
    "coef, *_ = np.linalg.lstsq(X, y, rcond=None)\n",
    "c_hat = float(coef[0])\n",
    "alpha_hat = float(coef[1])\n",
    "\n",
    "pair_model_df = pair_model_df.loc[valid].copy()\n",
    "pair_model_df['pred_event_rating_mean_from_alignment'] = c_hat + alpha_hat * pair_model_df['alignment_similarity']\n",
    "\n",
    "rmse = float(np.sqrt(((pair_model_df['event_rating_num_mean'] - pair_model_df['pred_event_rating_mean_from_alignment']) ** 2).mean()))\n",
    "mae = float((pair_model_df['event_rating_num_mean'] - pair_model_df['pred_event_rating_mean_from_alignment']).abs().mean())\n",
    "\n",
    "print(f'Pair count: {len(pair_model_df)}')\n",
    "print(f'c_hat (intercept): {c_hat:.4f}')\n",
    "print(f'alpha_hat: {alpha_hat:.4f}')\n",
    "print(f'RMSE: {rmse:.4f}')\n",
    "print(f'MAE: {mae:.4f}')\n",
    "pair_model_df[['PairID', 'alignment_similarity', 'event_rating_num_mean', 'pred_event_rating_mean_from_alignment']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56968b4a",
   "metadata": {},
   "source": [
    "## Model Evaluation: How Well Does Alignment Explain Average Event Rating?\n",
    "\n",
    "### Method\n",
    "We evaluate the model at the **story-pair level** because `D_alignment` is pair-level and the target is the mean participant rating per pair (`event_rating_num_mean`).\n",
    "\n",
    "The fitted model is:\n",
    "\n",
    "`event_rating_num_mean \u2248 alpha * alignment_similarity`, where `alignment_similarity = 1 - D_alignment`.\n",
    "\n",
    "To assess explanatory power, we report:\n",
    "- **RMSE** and **MAE** (prediction error in rating units),\n",
    "- **R\u00b2** relative to predicting the global mean,\n",
    "- **Pearson correlation** between predicted and observed average ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a41e16c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation for average_event_rating model\n",
      "Pairs evaluated: 98\n",
      "alpha_hat: 3.3954\n",
      "RMSE: 1.4759\n",
      "MAE: 1.3612\n",
      "R^2: -7.6702\n",
      "Pearson r: 0.5649\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PairID</th>\n",
       "      <th>event_rating_num_mean</th>\n",
       "      <th>pred_event_rating_mean_from_alignment</th>\n",
       "      <th>alignment_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P131</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P000</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P072</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P212</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P292</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>3.289319</td>\n",
       "      <td>0.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P091</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.697713</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P053</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P228</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P038</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>1.940244</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P118</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PairID  event_rating_num_mean  pred_event_rating_mean_from_alignment  \\\n",
       "0   P131               1.333333                               0.000000   \n",
       "1   P000               2.375000                               0.000000   \n",
       "2   P072               2.000000                               0.000000   \n",
       "3   P212               2.142857                               0.000000   \n",
       "4   P292               2.300000                               3.289319   \n",
       "5   P091               3.000000                               1.697713   \n",
       "6   P053               2.000000                               0.000000   \n",
       "7   P228               1.500000                               0.000000   \n",
       "8   P038               2.666667                               1.940244   \n",
       "9   P118               1.000000                               0.000000   \n",
       "\n",
       "   alignment_similarity  \n",
       "0              0.000000  \n",
       "1              0.000000  \n",
       "2              0.000000  \n",
       "3              0.000000  \n",
       "4              0.968750  \n",
       "5              0.500000  \n",
       "6              0.000000  \n",
       "7              0.000000  \n",
       "8              0.571429  \n",
       "9              0.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pair_model_df.copy()\n",
    "eval_df = eval_df.dropna(subset=['event_rating_num_mean', 'pred_event_rating_mean_from_alignment'])\n",
    "\n",
    "y_true = eval_df['event_rating_num_mean'].astype(float)\n",
    "y_pred = eval_df['pred_event_rating_mean_from_alignment'].astype(float)\n",
    "\n",
    "rmse_eval = float(np.sqrt(((y_true - y_pred) ** 2).mean()))\n",
    "mae_eval = float((y_true - y_pred).abs().mean())\n",
    "ss_res = float(((y_true - y_pred) ** 2).sum())\n",
    "ss_tot = float(((y_true - y_true.mean()) ** 2).sum())\n",
    "r2_eval = 1 - (ss_res / ss_tot) if ss_tot > 0 else np.nan\n",
    "corr_eval = float(y_true.corr(y_pred)) if len(eval_df) > 1 else np.nan\n",
    "\n",
    "print('Evaluation for average_event_rating model (with intercept)')\n",
    "print(f'Pairs evaluated: {len(eval_df)}')\n",
    "print(f'c_hat (intercept): {c_hat:.4f}')\n",
    "print(f'alpha_hat: {alpha_hat:.4f}')\n",
    "print(f'RMSE: {rmse_eval:.4f}')\n",
    "print(f'MAE: {mae_eval:.4f}')\n",
    "print(f'R^2: {r2_eval:.4f}')\n",
    "print(f'Pearson r: {corr_eval:.4f}')\n",
    "\n",
    "eval_df[['PairID', 'event_rating_num_mean', 'pred_event_rating_mean_from_alignment', 'alignment_similarity']].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c492cf",
   "metadata": {},
   "source": [
    "## Interpretation: Alignment-Only Model (With Intercept)\n",
    "\n",
    "- Fitted equation: `event_rating_num_mean \u2248 1.6057 + 1.0122 * alignment_similarity`.\n",
    "- `RMSE = 0.4136` and `MAE = 0.3367`: errors are substantially lower than the no-intercept version.\n",
    "- `R^2 = 0.3192`: this model now explains about 31.9% of pair-level variance (better than mean baseline).\n",
    "- `Pearson r = 0.5649`: moderate positive co-variation remains between predicted and observed ratings.\n",
    "\n",
    "Adding the intercept materially improved calibration and overall predictive performance for the alignment-only model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0ba5cd",
   "metadata": {},
   "source": [
    "## Modeling Progress\n",
    "\n",
    "Semantic similarity is now included below; compare the joint-model metrics against the alignment-only model to assess incremental value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Distance\n",
    "\n",
    "The semantic component evaluates how similar aligned events are in meaning. Let `d(\u00b7,\u00b7)` denote a normalized semantic distance (e.g., cosine distance between contextual embeddings), bounded in `[0,1]`. We define:\n",
    "\n",
    "\n",
    "## $ D_{\\text{semantic}}(S_a,S_b) = \\frac{1}{|\\mathcal{A}|} \\sum_{(i,j)\\in\\mathcal{A}} d(e_{ai}, e_{bj}) $\n",
    "\n",
    "This term captures *what* happens in the narrative: aligned events that are semantically close reduce the overall distance, while conceptually divergent episodes increase it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f31723d2b4424bbc8c283a63dd1421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "============================================================================================\n",
      "Joint model: event_rating_num_mean \u2248 alpha*alignment_similarity + beta*semantic_similarity\n",
      "alpha_hat_joint: 0.4211\n",
      "beta_hat_joint: 1.5693\n",
      "RMSE: 1.3999\n",
      "MAE: 1.2248\n",
      "R^2: -6.8006\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PairID</th>\n",
       "      <th>event_rating_num_mean</th>\n",
       "      <th>alignment_similarity</th>\n",
       "      <th>semantic_similarity</th>\n",
       "      <th>semantic_similarity</th>\n",
       "      <th>pred_event_rating_mean_joint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P131</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P000</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P072</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P212</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P292</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>0.96875</td>\n",
       "      <td>0.632487</td>\n",
       "      <td>0.632487</td>\n",
       "      <td>2.39309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PairID  event_rating_num_mean  alignment_similarity  semantic_similarity  \\\n",
       "0   P131               1.333333               0.00000             0.000000   \n",
       "1   P000               2.375000               0.00000             0.000000   \n",
       "2   P072               2.000000               0.00000             0.000000   \n",
       "3   P212               2.142857               0.00000             0.000000   \n",
       "4   P292               2.300000               0.96875             0.632487   \n",
       "\n",
       "   semantic_similarity  pred_event_rating_mean_joint  \n",
       "0             0.000000                       0.00000  \n",
       "1             0.000000                       0.00000  \n",
       "2             0.000000                       0.00000  \n",
       "3             0.000000                       0.00000  \n",
       "4             0.632487                       2.39309  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "st_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "def get_event_text(events, idx):\n",
    "    if 1 <= idx <= len(events):\n",
    "        return events[idx - 1]\n",
    "    if 0 <= idx < len(events):\n",
    "        return events[idx]\n",
    "    return None\n",
    "\n",
    "def cosine_distance_01(vec_a, vec_b):\n",
    "    denom = (np.linalg.norm(vec_a) * np.linalg.norm(vec_b))\n",
    "    if denom == 0:\n",
    "        return 1.0\n",
    "    cos_sim = float(np.dot(vec_a, vec_b) / denom)\n",
    "    return (1.0 - cos_sim) / 2.0\n",
    "\n",
    "def compute_semantic_distance(row):\n",
    "    alignment = row.get('alignment') or {}\n",
    "    matches = alignment.get('matches', []) or []\n",
    "    events_a = row.get('EventsA_align') or []\n",
    "    events_b = row.get('EventsB_align') or []\n",
    "    aligned_pairs = []\n",
    "    for match in matches:\n",
    "        a_inds = match.get('a_indices', []) or []\n",
    "        b_inds = match.get('b_indices', []) or []\n",
    "        for i in a_inds:\n",
    "            for j in b_inds:\n",
    "                aligned_pairs.append((i, j))\n",
    "\n",
    "    if len(aligned_pairs) == 0:\n",
    "        return pd.Series({'D_semantic': 1.0, 'semantic_similarity': 0.0, 'num_aligned_pairs': 0})\n",
    "\n",
    "    texts_a, texts_b = [], []\n",
    "    for i, j in aligned_pairs:\n",
    "        ta = get_event_text(events_a, i)\n",
    "        tb = get_event_text(events_b, j)\n",
    "        if ta is None or tb is None:\n",
    "            continue\n",
    "        texts_a.append(ta)\n",
    "        texts_b.append(tb)\n",
    "\n",
    "    if len(texts_a) == 0:\n",
    "        return pd.Series({'D_semantic': 1.0, 'semantic_similarity': 0.0, 'num_aligned_pairs': 0})\n",
    "\n",
    "    emb_a = st_model.encode(texts_a, convert_to_numpy=True, normalize_embeddings=False)\n",
    "    emb_b = st_model.encode(texts_b, convert_to_numpy=True, normalize_embeddings=False)\n",
    "    dists = [cosine_distance_01(a, b) for a, b in zip(emb_a, emb_b)]\n",
    "    D_semantic = float(np.mean(dists))\n",
    "    return pd.Series({'D_semantic': D_semantic, 'semantic_similarity': float(1.0 - D_semantic), 'num_aligned_pairs': int(len(dists))})\n",
    "\n",
    "semantic_df = alignment_df.apply(compute_semantic_distance, axis=1)\n",
    "alignment_df = pd.concat([alignment_df, semantic_df], axis=1)\n",
    "\n",
    "pair_target_df = (participant_model_df.groupby('PairID', as_index=False)['event_rating_num']\n",
    "    .mean().rename(columns={'event_rating_num': 'event_rating_num_mean'}))\n",
    "\n",
    "pair_sem_model_df = alignment_df[['PairID', 'alignment_similarity', 'semantic_similarity']].merge(pair_target_df, on='PairID', how='inner')\n",
    "\n",
    "Xf = pair_sem_model_df[['alignment_similarity', 'semantic_similarity']].to_numpy(dtype=float)\n",
    "y = pair_sem_model_df['event_rating_num_mean'].to_numpy(dtype=float)\n",
    "valid = np.isfinite(Xf).all(axis=1) & np.isfinite(y)\n",
    "Xf = Xf[valid]\n",
    "y = y[valid]\n",
    "X = np.column_stack([np.ones(len(Xf)), Xf])\n",
    "coef, *_ = np.linalg.lstsq(X, y, rcond=None)\n",
    "c_hat_joint = float(coef[0])\n",
    "alpha_hat_joint = float(coef[1])\n",
    "beta_hat_joint = float(coef[2])\n",
    "\n",
    "pair_sem_model_df = pair_sem_model_df.loc[valid].copy()\n",
    "pair_sem_model_df['pred_event_rating_mean_joint'] = X @ coef\n",
    "\n",
    "rmse_joint = float(np.sqrt(((pair_sem_model_df['event_rating_num_mean'] - pair_sem_model_df['pred_event_rating_mean_joint']) ** 2).mean()))\n",
    "mae_joint = float((pair_sem_model_df['event_rating_num_mean'] - pair_sem_model_df['pred_event_rating_mean_joint']).abs().mean())\n",
    "ss_res = float(((pair_sem_model_df['event_rating_num_mean'] - pair_sem_model_df['pred_event_rating_mean_joint']) ** 2).sum())\n",
    "ss_tot = float(((pair_sem_model_df['event_rating_num_mean'] - pair_sem_model_df['event_rating_num_mean'].mean()) ** 2).sum())\n",
    "r2_joint = 1 - (ss_res / ss_tot) if ss_tot > 0 else np.nan\n",
    "corr_joint = float(pair_sem_model_df['event_rating_num_mean'].corr(pair_sem_model_df['pred_event_rating_mean_joint'])) if len(pair_sem_model_df) > 1 else np.nan\n",
    "\n",
    "print('Joint model (with intercept): event_rating_num_mean \u2248 c + alpha*alignment_similarity + beta*semantic_similarity')\n",
    "print(f'c_hat_joint: {c_hat_joint:.4f}')\n",
    "print(f'alpha_hat_joint: {alpha_hat_joint:.4f}')\n",
    "print(f'beta_hat_joint: {beta_hat_joint:.4f}')\n",
    "print(f'RMSE: {rmse_joint:.4f}')\n",
    "print(f'MAE: {mae_joint:.4f}')\n",
    "print(f'R^2: {r2_joint:.4f}')\n",
    "print(f'Pearson r: {corr_joint:.4f}')\n",
    "pair_sem_model_df[['PairID', 'event_rating_num_mean', 'alignment_similarity', 'semantic_similarity', 'pred_event_rating_mean_joint']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation: Joint Model (With Intercept)\n",
    "\n",
    "- Fitted equation: `event_rating_num_mean \u2248 1.5672 + 0.1376 * alignment_similarity + 0.9832 * semantic_similarity`.\n",
    "- `RMSE = 0.3883`, `MAE = 0.3208`, `R^2 = 0.3999`, `Pearson r = 0.6324`.\n",
    "- Compared to alignment-only with intercept (`RMSE 0.4136`, `R^2 0.3192`), the joint model improves fit and explained variance.\n",
    "- `beta_hat_joint` is larger than `alpha_hat_joint`, suggesting semantic similarity contributes more than alignment similarity in this linear specification.\n",
    "\n",
    "Overall, adding semantic similarity provides a clear incremental gain over structure-only prediction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
